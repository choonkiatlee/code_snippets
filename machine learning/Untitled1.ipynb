{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "from sklearn.linear_model import (LinearRegression, Ridge, \n",
    "                                  Lasso, RandomizedLasso)\n",
    "from sklearn.feature_selection import RFE, f_regression\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(750, 14)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    " \n",
    "size = 750\n",
    "X = np.random.uniform(0, 1, (size, 14))\n",
    " \n",
    "#\"Friedamn #1‚Äù regression problem\n",
    "Y = (10 * np.sin(np.pi*X[:,0]*X[:,1]) + 20*(X[:,2] - .5)**2 +\n",
    "     10*X[:,3] + 5*X[:,4] + np.random.normal(0,1))\n",
    "#Add 3 additional correlated variables (correlated with X1-X3)\n",
    "X[:,10:] = X[:,:4] + np.random.normal(0, .025, (size,4))\n",
    " \n",
    "names = [\"x%s\" % i for i in range(1,15)]\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_val,x_test = X[:400],X[400:600],X[600:750]\n",
    "y_train,y_val,y_test = Y[:400],Y[400:600],Y[600:750]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestRegressor()\n",
    "rf.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores(model,x_test,y_test):\n",
    "    '''\n",
    "    Takes in x_test and y_test and produces precision / recall scores for the random forest\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    x_test, y_test -- numpy arrays\n",
    "    \n",
    "    Returns: \n",
    "    --------\n",
    "    precision_score, recall_score -- int\n",
    "    '''\n",
    "\n",
    "    forest_test_pred = model.predict(x_test)    \n",
    "    \n",
    "    precision_score = sklearn.metrics.precision_score(y_test, forest_test_pred)\n",
    "    recall_score = sklearn.metrics.recall_score(y_test, forest_test_pred)\n",
    "    y_scores_forest = model.predict_proba(x_test)[:,1]\n",
    "    \n",
    "    roc_score = sklearn.metrics.roc_auc_score(y_test, y_scores_forest)\n",
    "    return precision_score, recall_score, roc_score\n",
    "\n",
    "def generate_feature_scores(model, base_precision_score, base_recall_score, base_roc_score, as_percentage=False):\n",
    "    scores = []\n",
    "    \n",
    "    for i in range(30):\n",
    "        for i in range(x_test.shape[1]):\n",
    "            x_t = x_test.copy()\n",
    "            np.random.shuffle(x_t[:,i])\n",
    "            shuff_precision_score, shuff_recall_score, shuff_roc_score = get_scores(model, x_t,y_test)\n",
    "            \n",
    "            recall_score = base_recall_score - shuff_recall_score\n",
    "            precision_score = base_precision_score - shuff_precision_score\n",
    "            roc_score = base_roc_score - shuff_roc_score\n",
    "            \n",
    "            if as_percentage:\n",
    "                recall_score = recall_score / base_recall_score\n",
    "                precision_score = precision_score / base_precision_score\n",
    "                roc_score = roc_score / base_roc_score\n",
    "            \n",
    "            \n",
    "            scores.append({'feature':ordered_feature_names[i],'recall_score':recall_score,'precision_score':precision_score, 'roc_score':roc_score})\n",
    "        print((i/30)*100)\n",
    "    df = pd.DataFrame(scores)\n",
    "    return df \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_regression_scores(model,x_test,y_test):\n",
    "    '''\n",
    "    Takes in x_test and y_test and produces precision / recall scores for the random forest\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    x_test, y_test -- numpy arrays\n",
    "    \n",
    "    Returns: \n",
    "    --------\n",
    "    accuracy -- int\n",
    "    '''\n",
    "\n",
    "    \n",
    "    return sklearn.metrics.r2_score(y_test, rf.predict(x_test))\n",
    "\n",
    "def generate_regression_feature_scores(model, ordered_feature_names,base_accuracy, as_percentage=False):\n",
    "    scores = []\n",
    "    \n",
    "    for i in range(30):\n",
    "        for i in range(x_test.shape[1]):\n",
    "            x_t = x_test.copy()\n",
    "            np.random.shuffle(x_t[:,i])\n",
    "            shuff_acc = get_regression_scores(model, x_t,y_test)\n",
    "            \n",
    "            accuracy_score = base_accuracy - shuff_acc\n",
    "            \n",
    "            if as_percentage:\n",
    "                accuracy_score = accuracy_score / base_accuracy\n",
    "            \n",
    "            \n",
    "            scores.append({'feature':ordered_feature_names[i],'accuracy':accuracy_score})\n",
    "    df = pd.DataFrame(scores)\n",
    "    return df \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Model: Accuracy 0.8278109824639719\n",
      "---------------------------------------------------\n",
      "x4     0.258157\n",
      "x2     0.197320\n",
      "x11    0.161981\n",
      "x12    0.083428\n",
      "x14    0.068744\n",
      "x1     0.057981\n",
      "x5     0.056410\n",
      "x3     0.028748\n",
      "x13    0.023012\n",
      "x7     0.016375\n",
      "dtype: float64\n",
      "---------------------------------------------------\n",
      "         accuracy\n",
      "feature          \n",
      "x4       0.349530\n",
      "x2       0.244435\n",
      "x11      0.231150\n",
      "x5       0.084688\n",
      "x14      0.051676\n",
      "x1       0.046133\n",
      "x12      0.042515\n",
      "x13      0.029588\n",
      "x3       0.026349\n",
      "x8       0.004360\n"
     ]
    }
   ],
   "source": [
    "#print(y_test)\n",
    "forest_test_pred = rf.predict(x_test)  \n",
    "#print(forest_test_pred)\n",
    "\n",
    "base_accuracy_score = get_regression_scores(rf,x_test,y_test)\n",
    "print(\"Base Model: Accuracy {0}\".format(base_accuracy_score))\n",
    "\n",
    "important_features = pd.Series(data=rf.feature_importances_,index=names)\n",
    "important_features.sort_values(ascending=False,inplace=True)\n",
    "\n",
    "print ('---------------------------------------------------')\n",
    "print(important_features.head(10))\n",
    "    \n",
    "print('---------------------------------------------------')\n",
    "df = generate_regression_feature_scores(rf, names, base_accuracy_score, as_percentage = False)\n",
    "df = df.groupby('feature').mean()\n",
    "print(df.sort_values(by='accuracy',ascending=False).head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
